{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss= 1.2676 , 기울기 a = 0.1849, y절편= -0.4334\n",
      "Epoch: 6000, loss= 0.0152 , 기울기 a = -2.9211, y절편= 20.2981\n",
      "Epoch: 12000, loss= 0.0081 , 기울기 a = -3.5637, y절편= 24.8010\n",
      "Epoch: 18000, loss= 0.0055 , 기울기 a = -3.9557, y절편= 27.5463\n",
      "Epoch: 24000, loss= 0.0041 , 기울기 a = -4.2380, y절편= 29.5231\n",
      "Epoch: 30000, loss= 0.0033 , 기울기 a = -4.4586, y절편= 31.0675\n",
      "Epoch: 36000, loss= 0.0028 , 기울기 a = -4.6396, y절편= 32.3346\n",
      "Epoch: 42000, loss= 0.0024 , 기울기 a = -4.7930, y절편= 33.4086\n",
      "Epoch: 48000, loss= 0.0021 , 기울기 a = -4.9261, y절편= 34.3406\n",
      "Epoch: 54000, loss= 0.0019 , 기울기 a = -5.0436, y절편= 35.1636\n",
      "Epoch: 60000, loss= 0.0017 , 기울기 a = -5.1489, y절편= 35.9005\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "data=[[2,0],[4,0],[6,0],[8,1],[10,1],[12,1],[14,1]]\n",
    "x_data=[x_row[0] for x_row in data]\n",
    "y_data=[y_row[1] for y_row in data]\n",
    "\n",
    "# a와b의 값 임의로 정함(기울기, y절편 )\n",
    "\n",
    "a=tf.Variable(tf.random_normal([1],dtype=tf.float64,seed=0))\n",
    "b=tf.Variable(tf.random_normal([1],dtype=tf.float64,seed=0))\n",
    "\n",
    "\n",
    "#시그모이드 함수 \n",
    "y=1/(1+np.e**(a*x_data+b))\n",
    "\n",
    "#오차 구하기\n",
    "loss=-tf.reduce_mean(np.array(y_data)* tf.log(y)+(1-np.array(y_data))*tf.log(1-y))\n",
    "\n",
    "\n",
    "#학습값\n",
    "learning_rate=0.5\n",
    "\n",
    "\n",
    "#경사 하강법(오차 최소로 하는값 찾기)\n",
    "gradient_decent= tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "#결과값\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(60001):\n",
    "        sess.run(gradient_decent)\n",
    "        if i % 6000 ==0:\n",
    "            print(\"Epoch: %.f, loss= %.4f , 기울기 a = %.4f, y절편= %.4f\" % (i,sess.run(loss), sess.run(a), sess.run(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step= 300 , a1= 0.8385 , a2= -0.5748 , b=-2.4951 , loss=0.2627\n",
      "step= 600 , a1= 0.8248 , a2= -0.2887 , b=-3.9365 , loss=0.1898\n",
      "step= 900 , a1= 0.7323 , a2= 0.0403 , b=-4.9885 , loss=0.1488\n",
      "step= 1200 , a1= 0.6282 , a2= 0.3461 , b=-5.8236 , loss=0.1220\n",
      "step= 1500 , a1= 0.5295 , a2= 0.6183 , b=-6.5175 , loss=0.1031\n",
      "step= 1800 , a1= 0.4404 , a2= 0.8582 , b=-7.1116 , loss=0.0891\n",
      "step= 2100 , a1= 0.3613 , a2= 1.0701 , b=-7.6311 , loss=0.0784\n",
      "step= 2400 , a1= 0.2913 , a2= 1.2582 , b=-8.0929 , loss=0.0700\n",
      "step= 2700 , a1= 0.2293 , a2= 1.4262 , b=-8.5085 , loss=0.0631\n",
      "step= 3000 , a1= 0.1741 , a2= 1.5774 , b=-8.8864 , loss=0.0575\n",
      "공부한 시간 : 7 ,  과외 수업 횟수 : 6 \n",
      "합격 가능성:  85.78 %\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#실행할 때마다 같은 결과를 출력하기 위한 seed 값 설정\n",
    "seed=0\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "#x,y 의 데이터 값\n",
    "x_data=np.array([[2,3],[4,3],[6,4],[8,6],[10,7],[12,8],[14,9]])\n",
    "\n",
    "y_data=np.array([0,0,0,1,1,1,1]).reshape(7,1)\n",
    "\n",
    "\n",
    "#텐서플로에 데이터를 담기(place holder) \n",
    "X=tf.placeholder(tf.float64,shape=[None,2])\n",
    "Y=tf.placeholder(tf.float64,shape=[None,1])\n",
    "\n",
    "#기울기 a와 바이어스 b의 값을 임의로 정함\n",
    "a=tf.Variable(tf.random_uniform([2,1],dtype=tf.float64))    #[2,1] = 들어오는 값 2개 , 나가는 값 1개\n",
    "\n",
    "b=tf.Variable(tf.random_uniform([1],dtype=tf.float64))\n",
    "\n",
    "# y 시그모이드 함수의 방정식\n",
    "\n",
    "y=tf.sigmoid(tf.matmul(X,a)+b)\n",
    "\n",
    "#오차를 구하는 함수\n",
    "\n",
    "loss=-tf.reduce_mean(Y*tf.log(y)+(1-Y)*tf.log(1-y))\n",
    "\n",
    "#학습률 값 \n",
    "learning_rate=0.1\n",
    "\n",
    "#오차를 최소로 하는 값 찾기\n",
    "gradient_decent=tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "predicted=tf.cast(y>0.5 , dtype=tf.float64)\n",
    "accuracy= tf.reduce_mean(tf.cast(tf.equal(predicted,Y),dtype=tf.float64))\n",
    "\n",
    "#학습\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for i in range(3001):\n",
    "        \n",
    "        a_,b_,loss_, _ = sess.run([a,b,loss,gradient_decent], feed_dict={X: x_data ,Y:y_data})\n",
    "        \n",
    "        if (i+1) % 300 ==0:\n",
    "            print(\"step= %d , a1= %.4f , a2= %.4f , b=%.4f , loss=%.4f\" % (i+1, a_[0],a_[1],b_,loss_))\n",
    "\n",
    "    new_x=np.array([7,6]).reshape(1,2)          #공부한 시간과 과외수업 횟수\n",
    "\n",
    "    new_y=sess.run(y, feed_dict={X:new_x})\n",
    "\n",
    "    print(\"공부한 시간 : %d ,  과외 수업 횟수 : %d \" % (new_x[:,0],new_x[:,1]))\n",
    "    print(\"합격 가능성: %6.2f %%\" % (new_y*100))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# p93 입력받아 계산\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "공부한 시간 : 7 ,  과외 수업 횟수 : 6 \n",
      "합격 가능성:  99.98 %\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 코딩으로 XOR 문제 해결하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 값 : (0, 0)출력 값: 0\n",
      "입력 값 : (1, 0)출력 값: 1\n",
      "입력 값 : (0, 1)출력 값: 1\n",
      "입력 값 : (1, 1)출력 값: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "w11=np.array([-2,-2])\n",
    "w12=np.array([2,2])\n",
    "w2=np.array([1,1])\n",
    "b1=3\n",
    "b2=-1\n",
    "b3=-1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 퍼셉트론 함수\n",
    "def MLP(x,w,b):\n",
    "    y=np.sum(w*x)+ b\n",
    "    if y <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "    \n",
    "#NAND 게이트\n",
    "def NAND(x1,x2):\n",
    "    return MLP(np.array([x1,x2]),w11,b1)\n",
    "\n",
    "\n",
    "#or 게이트\n",
    "\n",
    "def OR(x1,x2):\n",
    "    return MLP(np.array([x1,x2]),w12,b2)\n",
    "\n",
    "#AND 게이트\n",
    "def AND(x1,x2):\n",
    "    return MLP(np.array([x1,x2]),w2,b3)\n",
    "\n",
    "#XOR 게이트\n",
    "def XOR(x1,x2):\n",
    "    return AND(NAND(x1,x2),OR(x1,x2))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for x in [(0,0),(1,0),(0,1),(1,1)]:\n",
    "        y=XOR(x[0],x[1])\n",
    "        print(\"입력 값 : \" + str(x)+ \"출력 값: \"+ str(y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  다층 퍼셉트론으로 XOR 문제 해결하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 값: (0, 0) 출력 값:0\n",
      "입력 값: (1, 0) 출력 값:1\n",
      "입력 값: (0, 1) 출력 값:1\n",
      "입력 값: (1, 1) 출력 값:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#가중치와 바이어스\n",
    "\n",
    "w11=np.array([-2,-2])\n",
    "w12=np.array([2,2])\n",
    "w2=np.array([1,1])\n",
    "\n",
    "b1= 3\n",
    "b2= -1\n",
    "b3= -1\n",
    "\n",
    "#퍼셉트론\n",
    "\n",
    "def MLP(x,w,b):\n",
    "    y=np.sum(w*x)+b\n",
    "    \n",
    "    if y<=0:\n",
    "        return 0\n",
    "    \n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "#NAND 게이트\n",
    "\n",
    "def NAND(x1,x2):\n",
    "    return MLP(np.array([x1,x2]),w11,b1)\n",
    "\n",
    "#OR 게이트\n",
    "\n",
    "def OR(x1,x2):\n",
    "    return MLP(np.array([x1,x2]),w12,b2)\n",
    "\n",
    "#and 게이트\n",
    "def AND(x1,x2):\n",
    "    return MLP(np.array([x1,x2]),w2,b3)\n",
    "\n",
    "#XOR 게이트\n",
    "def XOR(x1,x2):\n",
    "    return AND(NAND(x1,x2),OR(x1,x2))\n",
    "\n",
    "#x1,x2 값을 번갈아 대입해 가며 최종값 출력\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for x in [(0,0),(1,0),(0,1),(1,1)]:\n",
    "        y=XOR(x[0],x[1])\n",
    "        \n",
    "        print(\"입력 값: \"+ str(x) + \" 출력 값:\" + str(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# p122 모델 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "470/470 [==============================] - 1s 1ms/step - loss: 0.6614 - acc: 0.3149\n",
      "Epoch 2/30\n",
      "470/470 [==============================] - 0s 238us/step - loss: 0.1488 - acc: 0.8511\n",
      "Epoch 3/30\n",
      "470/470 [==============================] - 0s 238us/step - loss: 0.1488 - acc: 0.8511\n",
      "Epoch 4/30\n",
      "470/470 [==============================] - 0s 236us/step - loss: 0.1488 - acc: 0.8511\n",
      "Epoch 5/30\n",
      "470/470 [==============================] - 0s 244us/step - loss: 0.1488 - acc: 0.8511\n",
      "Epoch 6/30\n",
      "470/470 [==============================] - 0s 246us/step - loss: 0.1487 - acc: 0.8511\n",
      "Epoch 7/30\n",
      "470/470 [==============================] - 0s 240us/step - loss: 0.1487 - acc: 0.8511\n",
      "Epoch 8/30\n",
      "470/470 [==============================] - 0s 244us/step - loss: 0.1487 - acc: 0.8511\n",
      "Epoch 9/30\n",
      "470/470 [==============================] - 0s 246us/step - loss: 0.1487 - acc: 0.8511\n",
      "Epoch 10/30\n",
      "470/470 [==============================] - 0s 246us/step - loss: 0.1486 - acc: 0.8511\n",
      "Epoch 11/30\n",
      "470/470 [==============================] - 0s 236us/step - loss: 0.1498 - acc: 0.8447\n",
      "Epoch 12/30\n",
      "470/470 [==============================] - 0s 246us/step - loss: 0.1486 - acc: 0.8511\n",
      "Epoch 13/30\n",
      "470/470 [==============================] - 0s 240us/step - loss: 0.1485 - acc: 0.8511\n",
      "Epoch 14/30\n",
      "470/470 [==============================] - 0s 244us/step - loss: 0.1483 - acc: 0.8511\n",
      "Epoch 15/30\n",
      "470/470 [==============================] - 0s 244us/step - loss: 0.1485 - acc: 0.8511\n",
      "Epoch 16/30\n",
      "470/470 [==============================] - 0s 244us/step - loss: 0.1490 - acc: 0.8447\n",
      "Epoch 17/30\n",
      "470/470 [==============================] - 0s 253us/step - loss: 0.1479 - acc: 0.8489\n",
      "Epoch 18/30\n",
      "470/470 [==============================] - 0s 250us/step - loss: 0.1482 - acc: 0.8468\n",
      "Epoch 19/30\n",
      "470/470 [==============================] - 0s 250us/step - loss: 0.1476 - acc: 0.8511\n",
      "Epoch 20/30\n",
      "470/470 [==============================] - 0s 244us/step - loss: 0.1480 - acc: 0.8511\n",
      "Epoch 21/30\n",
      "470/470 [==============================] - 0s 250us/step - loss: 0.1475 - acc: 0.8511\n",
      "Epoch 22/30\n",
      "470/470 [==============================] - 0s 250us/step - loss: 0.1469 - acc: 0.8511\n",
      "Epoch 23/30\n",
      "470/470 [==============================] - 0s 248us/step - loss: 0.1466 - acc: 0.8511\n",
      "Epoch 24/30\n",
      "470/470 [==============================] - 0s 246us/step - loss: 0.1475 - acc: 0.8489\n",
      "Epoch 25/30\n",
      "470/470 [==============================] - 0s 253us/step - loss: 0.1470 - acc: 0.8511\n",
      "Epoch 26/30\n",
      "470/470 [==============================] - 0s 248us/step - loss: 0.1466 - acc: 0.8511\n",
      "Epoch 27/30\n",
      "470/470 [==============================] - 0s 255us/step - loss: 0.1472 - acc: 0.8511\n",
      "Epoch 28/30\n",
      "470/470 [==============================] - 0s 242us/step - loss: 0.1471 - acc: 0.8511\n",
      "Epoch 29/30\n",
      "470/470 [==============================] - 0s 255us/step - loss: 0.1470 - acc: 0.8489\n",
      "Epoch 30/30\n",
      "470/470 [==============================] - 0s 246us/step - loss: 0.1461 - acc: 0.8532\n",
      "470/470 [==============================] - 0s 127us/step\n",
      "\n",
      " Accuracy: 0.8511\n"
     ]
    }
   ],
   "source": [
    "#딥러닝을 구동하는데 필요한 케라스 함수 불러오기\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense \n",
    "import numpy \n",
    "import tensorflow as tf\n",
    "from pandas import Series,DataFrame\n",
    "import pandas\n",
    "#실행할 때마다 같은 결과를 출력하기 위해 설정하는 부분\n",
    "seed=0\n",
    "numpy.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "#준비된 수술 환자 데이터 불러들이기\n",
    "Data_set=numpy.loadtxt(\"C:/Users/Affinity/Desktop/lecture/006958-master/006958-master/deeplearning/dataset/ThoraricSurgery.csv\",\n",
    "                              delimiter=\",\")\n",
    "\n",
    "\n",
    "\n",
    "# 환자의 기록과 수술 결과를 x,y 구분\n",
    "\n",
    "X= Data_set[:,0:17]\n",
    "Y= Data_set[:,17]\n",
    "\n",
    "\n",
    "#딥러닝 구조를 결정\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Dense(30,input_dim=17,activation=\"relu\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "\n",
    "#딥러닝을 실행\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "model.fit(X,Y,epochs=30,batch_size=10)\n",
    "\n",
    "#결과 출력\n",
    "print(\"\\n Accuracy: %.4f\" % (model.evaluate(X,Y)[1]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Keras",
   "language": "python",
   "name": "keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
