{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# p787 엑셀파일 분석 (웹의 다양한 데이터 형식)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "\n",
    "#엑셀 파일 열기\n",
    "\n",
    "filename=\"C:/Users/Affinity/Desktop/lecture/modeule04/ch01/stats_104102.xlsx\"\n",
    "book=openpyxl.load_workbook(filename)\n",
    "\n",
    "#맨 앞의 시트 추출 \n",
    "\n",
    "sheet=book.worksheets[0]\n",
    "\n",
    "#시트의 각 행을 순서대로 추출하기 \n",
    "data=[]\n",
    "for row in sheet.rows:\n",
    "    data.append([\n",
    "        row[0].value,\n",
    "        row[9].value\n",
    "    ])\n",
    "    \n",
    "print(data)   \n",
    "# 필요없는 줄 제거\n",
    "\n",
    "del data[0]\n",
    "print(data)\n",
    "del data[0]\n",
    "print(data)\n",
    "del data[0]    \n",
    "\n",
    "#데이터를 인구 순서로 정렬합니다.\n",
    "data= sorted(data,key=lambda x:x[1])\n",
    "\n",
    "for i,a in enumerate(data):\n",
    "    if(i>=5): break\n",
    "        \n",
    "    print(i+1,a[0],int(a[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### p796 한국어분석 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Twitter\n",
    "\n",
    "twitter=Twitter()\n",
    "\n",
    "malist=twitter.pos(\"아버지 가방에 들어가신다.\", norm=True,stem=True)\n",
    "print(malist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 형태소 분석기별 출력 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import  codecs\n",
    "from bs4 import BeautifulSoup\n",
    "from konlpy.tag import Twitter, Okt,Komoran,Hannanum,Kkma\n",
    "ok=Okt(); kmr=Komoran(); hnn=Hannanum(); kma=Kkma() ; twitter= Twitter()\n",
    "import time\n",
    "\n",
    "start=time.time()\n",
    "malist=twitter.morphs(\"아버지 가방에 들어가신다.\")\n",
    "print(malist )\n",
    "print(time.time()-start)\n",
    "malist1=ok.morphs(\"아버지 가방에 들어가신다.\")\n",
    "print(malist1 )\n",
    "print(time.time()-start)\n",
    "malist2=kmr.morphs(\"아버지 가방에 들어가신다.\")\n",
    "print(malist2)\n",
    "print(time.time()-start)\n",
    "malist4=hnn.morphs(\"아버지 가방에 들어가신다.\")\n",
    "print(malist4)\n",
    "print(time.time()-start)\n",
    "malist5=kma.morphs(\"아버지 가방에 들어가신다.\")\n",
    "print(malist5)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  codecs\n",
    "from bs4 import BeautifulSoup\n",
    "from konlpy.tag import Twitter, Okt,Komoran,Hannanum,Kkma\n",
    "\n",
    "#ok=Okt(); kmr=Komoran(); hnn=Hannanum(); kma=Kkma()\n",
    "#utf-16 인코딩으로 파일을 열고 글자를 출력\n",
    "\n",
    "fp=codecs.open(\"C:/Users/Affinity/Desktop/lecture/modeule04/ch02/BEXX0003.txt\",\"r\",encoding=\"utf-16\")\n",
    "\n",
    "soup=BeautifulSoup(fp,\"html.parser\")\n",
    "body=soup.select_one(\"body > text\")\n",
    "text=body.getText()\n",
    "\n",
    "\n",
    "#텍스트를 한 줄 씩 처리\n",
    "twitter= Twitter()\n",
    "word_dic={}\n",
    "lines=text.split(\"\\n\")\n",
    "\n",
    "for line in lines:\n",
    "    malist=twitter.pos(line)\n",
    " \n",
    "    for word in malist:\n",
    "        \n",
    "   \n",
    "        if word[1]==\"Noun\":                   #명사 확인\n",
    "            if not (word[0] in word_dic):\n",
    "                word_dic[word[0]]=0\n",
    "              \n",
    "            word_dic[word[0]]+=1              #카운트하기\n",
    "               \n",
    "            #print(word_dic)\n",
    "keys=sorted(word_dic.items(), key=lambda x:x[1], reverse=True)\n",
    "#print(keys)\n",
    "for word, count in keys[:50]:\n",
    "    print(\"{0}({1}) \".format(word,count),end=\"\")\n",
    "    \n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# p779 워드클라우드\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "#xprtmxm vkdlf qnffjdhrl\n",
    "\n",
    "text=open(\"C:/Users/Affinity/Desktop/lecture/modeule04/ch02/constitution.txt\").read()\n",
    "\n",
    "#단어별 빈도 계산(공백으로 분리된 단어)\n",
    "\n",
    "wordcloud=WordCloud().generate(text)\n",
    "wordcloud.words_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "plt.imshow(wordcloud,interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#단어별 빈도 계산\n",
    "wordcloud=WordCloud(max_font_size=40).generate(text)\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.imshow(wordcloud,interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# p801 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud\n",
    "from wordcloud import STOPWORDS\n",
    "\n",
    "#이미지 불러오기\n",
    "alice_mask=np.array(Image.open(\"C:/Users/Affinity/Desktop/lecture/modeule04/ch02/alice_mask.png\"))\n",
    "\n",
    "#삭제할 단어와 추가\n",
    "stopwords=set(STOPWORDS)\n",
    "stopwords.add(\"said\")\n",
    "\n",
    "#텍스트 파일 불러오기\n",
    "text=open(\"C:/Users/Affinity/Desktop/lecture/modeule04/ch02/constitution.txt\").read()\n",
    "\n",
    "#e단어별 빈도 계산 \n",
    "wordcloud=WordCloud(background_color=\"white\",max_words=2000, mask=alice_mask,stopwords=stopwords)\n",
    "wordcloud=wordcloud.generate(text)\n",
    "\n",
    "#색상 함수\n",
    "r=lambda: np.random.randint(0,255)\n",
    "\n",
    "#color=lambda: (r, r, r)\n",
    "def wc_color(word ,font_size,position,orientation,randomstate=None,**kwargs):\n",
    "    return (r(),r(),r())\n",
    "             \n",
    "#워드 클라우드 작성\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.imshow(wordcloud.recolor(color_func= wc_color, random_state=2), interpolation= \"bilinear\")\n",
    "             \n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from wordcloud import STOPWORDS\n",
    "from wordcloud import ImageColorGenerator           #이미지에서 색 추출\n",
    "\n",
    "#이미지 불러오기\n",
    "alice_color=np.array(Image.open(\"C:/Users/Affinity/Desktop/lecture/modeule04/ch02/alice_color.png\"))\n",
    "image_colors=ImageColorGenerator(alice_color)  # 이미지에서 색 추출\n",
    "\n",
    "#삭제할 단어와 추가\n",
    "stopwords=set(STOPWORDS)\n",
    "stopwords.add(\"said\")\n",
    "\n",
    "#텍스트 파일 불러오기\n",
    "text=open(\"C:/Users/Affinity/Desktop/lecture/modeule04/ch02/constitution.txt\").read()\n",
    "\n",
    "#단어별 빈도 계산(공백으로 분리된 단어)\n",
    "wordcloud=WordCloud(background_color=\"white\",max_words=2000, mask=alice_color, stopwords=stopwords)\n",
    "\n",
    "wordcloud=wordcloud.generate(text)\n",
    "\n",
    "#워드클라우드 작성\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# p804 NLTK   패키지이용 한글 워드 클라우드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from konlpy.corpus import kolaw\n",
    "from konlpy.tag import Twitter\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud\n",
    "from wordcloud import ImageColorGenerator     #이미지에서 색 추출\n",
    "\n",
    "t=Twitter()\n",
    "\n",
    "#텍스트 파일 불러오기\n",
    "ko_con_text=open(\"C:/Users/Affinity/Desktop/lecture/modeule04/ch02/speech.txt\", encoding=\"utf-8\").read()\n",
    "\n",
    "ko_con_text\n",
    "\n",
    "#명사 추출\n",
    "tokens_ko=t.nouns(ko_con_text)\n",
    "tokens_ko\n",
    "\n",
    "#단어 삭제\n",
    "stop_words=[]\n",
    "f=open(\"C:/Users/Affinity/Desktop/lecture/modeule04/ch02/stop_word.txt\",encoding=\"utf-8\")\n",
    "\n",
    "lines=f.readlines()\n",
    "\n",
    "for x in lines :\n",
    "    stop_words.append(x.strip())\n",
    "    \n",
    "stop_words\n",
    "tokens_ko=[each_word for each_word in tokens_ko if each_word not in stop_words]\n",
    "tokens_ko\n",
    "\n",
    "sel_word=nltk.Text(tokens_ko)\n",
    "data=sel_word.vocab().most_common(1000)\n",
    "tmp_data=dict(data)\n",
    "\n",
    "\n",
    "#단어별 빈도 계산(공백으로 분리된 단어)\n",
    "wordcloud=WordCloud(font_path=\"C:/Windows/Fonts/HYBDAM.ttf\",background_color=\"white\")\n",
    "wrodcloud=wordcloud.generate_from_frequencies(tmp_data)\n",
    "\n",
    "#워드클라우드 작성\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지 불러오기\n",
    "#image_colors=ImageColorGenerator   이미지에서 색 추출\n",
    "\n",
    "korea_color=np.array(Image.open(\"C:/Users/Affinity/Desktop/lecture/modeule04/ch02/south-korea-flag.png\"))\n",
    "image_colors=ImageColorGenerator(korea_color)   # 이미지에서 색 추출\n",
    "\n",
    "# 단어별 빈도 계산\n",
    "wordcloud=WordCloud(font_path=\"C:/Windows/Fonts/HYBDAM.ttf\",relative_scaling=0.2,\n",
    "                    mask=korea_color,background_color=\"white\",min_font_size=1,\n",
    "                    max_font_size=80)\n",
    "\n",
    "wordcloud=wordcloud.generate_from_frequencies(tmp_data)\n",
    "\n",
    "\n",
    "#워드클라우드 작성\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# p807 문장을 벡터로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "from bs4 import BeautifulSoup\n",
    "from konlpy.tag import Twitter\n",
    "from gensim.models import word2vec\n",
    "\n",
    "# utf-16 인코딩으로 파일을 열고 글자를 출력하기\n",
    "fp=codecs.open(\"C:/Users/Affinity/Desktop/lecture/modeule04/ch02/BEXX0003.txt\",\"r\",encoding=\"utf-16\")\n",
    "soup=BeautifulSoup(fp,\"html.parser\")\n",
    "body=soup.select_one(\"body >  text\")\n",
    "text=body.getText()\n",
    "\n",
    "twitter=Twitter()\n",
    "results=[]\n",
    "lines=text.split(\"\\n\\n\")\n",
    "\n",
    "for line in lines:\n",
    "    #형태소 분석하기\n",
    "    # 단어의 기본형 사용\n",
    "    \n",
    "    malist=twitter.pos(line,norm=True,stem=True)\n",
    "    r=[]\n",
    "    \n",
    "    for word in malist:\n",
    "        #어미/조사/구두점 등을 대상에서 제외\n",
    "        if not word[1] in [\"Josa\",\"Eomi\",\"Punctuation\"]:\n",
    "            r.append(word[0])\n",
    "    r1=(\" \" .join(r)).strip()\n",
    "    results.append(r1)\n",
    "    print(r1)\n",
    "    \n",
    "#파일로 출력하기\n",
    "wakati_file=\"toji.wakati\"\n",
    "with open(wakati_file, \"w\", encoding=\"utf-8\") as fp:\n",
    "    fp.write(\"\\n\".join(results))\n",
    "    \n",
    "#Word2Vec 모델 만들기\n",
    "data=word2vec.LineSentence(wakati_file)         #텍스트 읽어 들이기\n",
    "model=word2vec.Word2Vec(data,size=200, window=10, hs=1, min_count=2, sg=1)\n",
    "model.save(\"C:/Users/Affinity/Desktop/lecture/modeule04/ch02/toji.model\")\n",
    "print(\"ok\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=word2vec.Word2Vec.load(\"C:/Users/Affinity/Desktop/lecture/modeule04/ch02/toji.model\")\n",
    "model.most_similar(\"각\")         #입력한 단어와 유사한 단어\n",
    "\n",
    "model.similarity(\"땅\",\"조상\")                  # 두 단어 사이의 유사도\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 땅 +조상 - 젊은이  선형결과\n",
    "model.most_similar(positive=[\"땅\",\"조상\"], negative=[\"젊은이\"], topn=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# p818  베이즈 정리로 텍스트 분류\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 베이지안 파일은 따로 만들었음\n",
    "\n",
    "#\"bayes.py\" 불러오기\n",
    "import sys\n",
    "sys.path.insert(0, 'C:/Users/Affinity/Desktop/lecture/')        # bayes 파일 사용할때 마다 넣어주기\n",
    "\n",
    "from bayes import BayesianFilter\n",
    "bf=BayesianFilter()\n",
    "\n",
    "#텍스트 학습\n",
    "bf.fit(\"파격 세일 - 오늘까지만 30% 할인\",\"광고\")\n",
    "bf.fit(\"쿠폰 선물 & 무료 배송\", \"광고\")\n",
    "bf.fit(\"헌데계 백화점 세일\",\"광고\")\n",
    "bf.fit(\"봄과 함께 찾아온 따뜻한 신제품 소직\",\"광고\")\n",
    "bf.fit(\"인기 제품 기간 한정 세일\",\"광고\")\n",
    "bf.fit(\"오늘 일정 확인\",\"중요\")\n",
    "bf.fit(\"프로젝트 진행 상황 보고\",\"중요\")\n",
    "bf.fit(\"계약 잘 부탁드립니다\",\"중요\")\n",
    "bf.fit(\"회의 일정이 등록되었습니다\",\"중요\")\n",
    "bf.fit(\"오늘 일정이 없습니다\",\"광고\")\n",
    "\n",
    "#예측\n",
    "pre,scorelist=bf.predict(\"재고 정리 할인, 무료 배송\")\n",
    "print(\"rufrhk =\", pre)\n",
    "print(scorelist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "초기\n",
      "   type                                               text\n",
      "0  spam  Free msg: Single? Find a partner in your area!...\n",
      "1  spam  Want to funk up ur fone with a weekly new tone...\n",
      "2   ham  Even my brother is not like to speak with me. ...\n",
      "3   ham  Wow. I never realized that you were so embaras...\n",
      "4  spam  URGENT This is our 2nd attempt to contact U. Y...\n",
      "5   ham           Yes..gauti and sehwag out of odi series.\n",
      "6  spam  Free Msg: Ringtone!From: http://tms. widelive.... \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -253.24259426804468), ('spam', -219.48238682631543)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -246.779447975363), ('spam', -207.62302473730347)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -109.57024123977561), ('spam', -130.49161490770229)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -380.28286096938734), ('spam', -475.17797606234086)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -249.6339317181357), ('spam', -192.96682501338427)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -64.03960816950247), ('spam', -71.42815207779262)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -228.98694068220473), ('spam', -198.26571459458833)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -138.3804353635761), ('spam', -179.0353761546468)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -117.42084225264533), ('spam', -94.94604541890261)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -176.58843811449287), ('spam', -147.3281156154263)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -271.0467399437702), ('spam', -211.26594663976607)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -36.04207349864356), ('spam', -45.25437016762456)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -35.811856110805515), ('spam', -48.38089846231134)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -111.46477783050692), ('spam', -121.26379676637505)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -192.40912837883516), ('spam', -162.50523761836774)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -67.70467840065108), ('spam', -75.84424510714074)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -126.39867684562428), ('spam', -106.91045210155342)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -138.90571180414722), ('spam', -170.76849684934615)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -40.84639882555633), ('spam', -57.68861126808267)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -272.54220063037405), ('spam', -223.2700251847912)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -40.41970766189517), ('spam', -42.54773941317657)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -301.24144464407027), ('spam', -257.60757428948637)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -234.7748878020788), ('spam', -197.87759529034952)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -161.46100514086032), ('spam', -127.31882782725907)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -272.139378279185), ('spam', -210.74556543074885)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -46.867847652971975), ('spam', -59.84551126103215)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -278.00475470853166), ('spam', -211.36788251623375)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -219.6363076808512), ('spam', -257.80346602562076)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -228.30688598915597), ('spam', -208.0535657306019)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -22.75696885226001), ('spam', -21.301845818901583)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -103.97856073660834), ('spam', -99.82452752984251)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -194.6194652316558), ('spam', -238.30304491222216)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -186.93366736766285), ('spam', -223.13846186242597)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -66.97833996581636), ('spam', -71.46477200924585)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -164.65839946119897), ('spam', -183.3256201718025)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -216.61352703559342), ('spam', -260.3200894584733)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -95.86981630862871), ('spam', -127.01417423619984)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -190.93582258018714), ('spam', -210.52642862655767)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -252.17815937094755), ('spam', -203.9817022509809)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -282.94264476280273), ('spam', -234.08229082241624)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -233.08807819816312), ('spam', -174.08611650327202)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -269.2927996447912), ('spam', -229.27255569472666)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -231.16791202678922), ('spam', -169.18778595914023)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -95.01957284768874), ('spam', -97.57259831023069)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -219.7420926932604), ('spam', -176.62850676360273)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -122.11872708737923), ('spam', -144.46163047883965)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -113.39196794246155), ('spam', -132.2368313247911)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -201.36740047158307), ('spam', -157.93108126592284)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -99.73608734161196), ('spam', -117.95927804547755)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -252.72046542412906), ('spam', -193.26601199727227)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -56.67596397386168), ('spam', -40.0564892894664)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -219.1695425112893), ('spam', -181.51123591897118)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -251.03059976109907), ('spam', -288.7799463151749)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -153.3293305886831), ('spam', -193.7789478503087)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -91.21235897681393), ('spam', -104.35913902166969)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -188.12264970736223), ('spam', -152.96377906822113)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -68.4688621277764), ('spam', -89.81564198391774)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -274.78520520720315), ('spam', -233.23492414097706)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -208.07828953252488), ('spam', -257.4694290383948)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -57.01705090105813), ('spam', -71.33634452853951)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -119.74825639634494), ('spam', -128.5551355550538)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -206.3982786875378), ('spam', -215.59406345514964)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -314.74436469188754), ('spam', -243.3819164825915)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -124.01576606471981), ('spam', -111.59802012700176)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -194.54996766743568), ('spam', -196.81651636362443)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -160.77433178782087), ('spam', -187.63867689287594)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -37.577142281760054), ('spam', -46.97628606348535)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -228.49734083740063), ('spam', -188.93726009955702)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -76.71769538105914), ('spam', -96.70540312357207)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -280.47930590880134), ('spam', -229.0397098716758)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -29.68879274560181), ('spam', -38.6329735818278)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -282.350312916039), ('spam', -230.63290954291793)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -102.23264899861556), ('spam', -84.08354127230034)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -292.7831123510897), ('spam', -349.4783921751378)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -322.28739441961267), ('spam', -235.63400104375143)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -50.73106540908169), ('spam', -63.18634375004679)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -76.33634448946643), ('spam', -96.65692368035467)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -83.67029048763624), ('spam', -103.46974981925887)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -212.7084211200284), ('spam', -188.49582456578915)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -38.69126022322037), ('spam', -54.16773569511107)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -118.88948785923071), ('spam', -141.5321559793582)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -119.0293594771438), ('spam', -147.10712835609732)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -173.0385458614786), ('spam', -216.1498027967418)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -299.80339952590344), ('spam', -258.91040188213)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -143.93026586400742), ('spam', -126.56744699272984)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -241.47792560209678), ('spam', -215.4150936156362)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -228.32920861543303), ('spam', -178.57826339514685)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -99.79740698612089), ('spam', -127.14219427218595)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -37.214844693892594), ('spam', -38.97472287554986)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -203.25707664715628), ('spam', -241.46234224304865)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -216.19928566914015), ('spam', -197.0040397716178)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -79.34786727533613), ('spam', -89.10560491660064)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -175.48795079235683), ('spam', -164.44052356504324)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -73.91642288297327), ('spam', -89.97507884555785)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -326.56334257624724), ('spam', -259.2902704027418)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -262.48490389491656), ('spam', -200.17430235581745)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -89.03298898795586), ('spam', -109.9409183021007)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -208.2971200332899), ('spam', -173.69899592622727)] \n",
      "\n",
      "예측 결과 : ham\n",
      "예측 점수\n",
      " [('ham', -28.037811519934184), ('spam', -36.04270641638197)] \n",
      "\n",
      "예측 결과 : spam\n",
      "예측 점수\n",
      " [('ham', -290.168585776984), ('spam', -252.43753323500184)] \n",
      "\n",
      "['spam', 'spam', 'ham', 'ham', 'spam', 'ham', 'spam', 'ham', 'spam', 'spam', 'spam', 'ham', 'ham', 'ham', 'spam', 'ham', 'spam', 'ham', 'ham', 'spam', 'ham', 'spam', 'spam', 'spam', 'spam', 'ham', 'spam', 'ham', 'spam', 'spam', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'spam', 'spam', 'spam', 'spam', 'ham', 'spam', 'ham', 'ham', 'spam', 'ham', 'spam', 'spam', 'spam', 'ham', 'ham', 'ham', 'spam', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'spam', 'spam', 'ham', 'ham', 'ham', 'spam', 'ham', 'spam', 'ham', 'spam', 'spam', 'ham', 'spam', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'spam', 'spam', 'spam', 'spam', 'ham', 'ham', 'ham', 'spam', 'ham', 'spam', 'ham', 'spam', 'spam', 'ham', 'spam', 'ham', 'spam'] \n",
      "\n",
      "예측률 :  98.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free msg: Single? Find a partner in your area!...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Want to funk up ur fone with a weekly new tone...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Wow. I never realized that you were so embaras...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>URGENT This is our 2nd attempt to contact U. Y...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes..gauti and sehwag out of odi series.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free Msg: Ringtone!From: http://tms. widelive....</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text predict\n",
       "0  spam  Free msg: Single? Find a partner in your area!...    spam\n",
       "1  spam  Want to funk up ur fone with a weekly new tone...    spam\n",
       "2   ham  Even my brother is not like to speak with me. ...     ham\n",
       "3   ham  Wow. I never realized that you were so embaras...     ham\n",
       "4  spam  URGENT This is our 2nd attempt to contact U. Y...    spam\n",
       "5   ham           Yes..gauti and sehwag out of odi series.     ham\n",
       "6  spam  Free Msg: Ringtone!From: http://tms. widelive....    spam"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'C:/Users/Affinity/Desktop/lecture/')   \n",
    "from pandas import Series, DataFrame\n",
    "from numpy import nan as NA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bayes import BayesianFilter\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"C:/Users/Affinity/Desktop/lecture/modeule04/ch02/sms_spam.csv\",\n",
    "                header=0,\n",
    "                encoding=\"cp437\")\n",
    "df.head(7)\n",
    "\n",
    "\n",
    "bf = BayesianFilter()\n",
    "for i in df.index:\n",
    "    bf.fit(df.text[i], df.type[i])\n",
    "    \n",
    "      \n",
    "df_test = pd.read_csv(\n",
    "    \"C:/Users/Affinity/Desktop/lecture/modeule04/ch02/sms_spam_test.csv\",\n",
    "    header=0,\n",
    "    encoding=\"cp437\"\n",
    "    )\n",
    "print(df_test.head(7), \"\\n\")\n",
    "\n",
    "prediced=[]\n",
    "for x in df_test.text:\n",
    "    pre, scorelist = bf.predict(x)\n",
    "    prediced.append(pre)\n",
    "\n",
    "    print(\"예측 결과 :\", pre)\n",
    "    print(\"예측 점수\\n\", scorelist, \"\\n\")\n",
    "print(prediced, \"\\n\")\n",
    "\n",
    "df_test[\"predict\"] = prediced\n",
    "print(f\"예측률 : {df_test.type.eq(df_test.predict).mean()*100:5.1f}\")\n",
    "df_test.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mypython",
   "language": "python",
   "name": "mypython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
