{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Affinity\\.conda\\envs\\keras\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Affinity\\.conda\\envs\\keras\\lib\\site-packages\\numpy\\.libs\\libopenblas.IPBC74C7KURV7CB2PKT5Z5FNR3SIBV4J.gfortran-win_amd64.dll\n",
      "C:\\Users\\Affinity\\.conda\\envs\\keras\\lib\\site-packages\\numpy\\.libs\\libopenblas.TXA6YQSD3GCQQC22GEQ54J2UDCXDXHWN.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy.core._ufunc_config'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e8ad342e6407>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# 필요한 라이브러리 불러들임\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\keras\\lib\\site-packages\\numpy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\keras\\lib\\site-packages\\numpy\\core\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumerictypes\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[0mmultiarray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_typeDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msctypeDict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumeric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mnumeric\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfromnumeric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\keras\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_exceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTooHardError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAxisError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_asarray\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0masarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_ufunc_config\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0merrstate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[0mbitwise_not\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minvert\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy.core._ufunc_config'"
     ]
    }
   ],
   "source": [
    "#============================================================#\n",
    "# 예제 8: 인물 이미지 변형을 위한 CycleGAN 구현\n",
    "#============================================================#\n",
    "\n",
    "\"\"\"\n",
    "이 예제에서 사용하는 이미지 데이터는 DCGAN에서 사용한 인물 흑백 이미지 20장이다. \n",
    "20장 중 10장은 정상 이미지 x(도메인 A), 10장은 회전한 이미지로 변형하여 y(도메인 B)로 사용한다. \n",
    "도메인 A에 속하는 이미지를 입력하면 회전한 이미지로 변형하고, 도메인 B에 속하는 \n",
    "회전한 이미지를 입력하면 정상 이미지로 변형하는 CycleGAN을 만드는 것이 목적이다. \n",
    "단, 도메인 A에 속하는 이미지를 회전한 이미지가 도메인 B에 존재한다고\n",
    "확신할 수 없다는 사실에 주의한다.\n",
    "\n",
    "생성자(G=G_AB, F=G_BA)와 판별자(D_A, D_B)는 입력층, 1개의 은닉층 및 출력층으로\n",
    "구성된 전방향 신경망이다. 인물 이미지는 45*40 = 1800 픽셀의 이미지이므로 생성자의 출\n",
    "력층은 1,800개의 출력노드를 가진다. 모든 출력노드에 적용되는 활성함수로 시그모이드 함\n",
    "수를 사용하고 모든 가중치는 Xavier 초기치를 사용한다.\n",
    "\"\"\"\n",
    "\n",
    "# 필요한 라이브러리 불러들임 \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image as Im\n",
    "import os\n",
    "import glob  \n",
    "\n",
    "\n",
    "# 그래프 리셋\n",
    "tf.reset_default_graph() \n",
    "# 재현성을 위해 시드 지정\n",
    "tf.set_random_seed(1)\n",
    "\n",
    "#--------------------------------------------------\n",
    "# data 불러오기\n",
    "#--------------------------------------------------\n",
    " \n",
    "#os.chdir('C:/Users/admin/Dropbox/저서/텐서플로_딥러닝/GANs_tensorflow/')\n",
    "files=glob.glob('C:/Users/Affinity/Desktop/lecture/module7/AE_Gan/face20/*.png')\n",
    "\n",
    "img=[]          \n",
    "for file in files:\n",
    "    a=Im.open(file) \n",
    "    a=a.convert('L') # 흑백화면으로 \n",
    "    a1=np.array(a)\n",
    "    img.append(a1)        \n",
    "    \n",
    "\n",
    "xr=np.asarray(img)/255. # convert list to array\n",
    "\n",
    "nr=np.prod(xr.shape[1:3]) # 45*40=1800\n",
    "Xr=np.reshape(xr,[len(img),nr]) #=[20,1800]\n",
    "\n",
    "\n",
    "import scipy.ndimage.interpolation\n",
    "# Real image\n",
    "X_rA = Xr[:10]\n",
    "# Rotated image\n",
    "X_rB = Xr[10:].reshape(-1, 45, 40)\n",
    "X_rB = scipy.ndimage.interpolation.rotate(X_rB, 90, axes=(1, 2))\n",
    "X_rB = X_rB.reshape(-1, 45*40)\n",
    "\n",
    "# divide to train and test\n",
    "XA=X_rA[0:2,:]\n",
    "X_trainA=X_rA[2:10,:]\n",
    "XB=X_rB[0:2,:]\n",
    "X_trainB=X_rB[2:10,:]\n",
    "\n",
    "# 훈련용과 시험용 이미지 개수와 입력 변수의 수\n",
    "sample_size= X_trainA.shape[0] #8 \n",
    "sample_size_test= XA.shape[0] #2 \n",
    "X_dim = X_trainA.shape[1] #=1800\n",
    "#-------------------------------------------\n",
    "# 매개변수 설정\n",
    "#-------------------------------------------\n",
    "# 생성자의 두 은닉층 크기: 128\n",
    "# 비판자의 두 은닉층 크기: 128\n",
    "# 미니배치 크기: 20\n",
    "# 반복 수: 300\n",
    "# 학습률 : 0.001\n",
    "\n",
    "learning_rate = 0.001\n",
    "batch_size = 2\n",
    "epochs =600 # no. of epochs\n",
    "h_dim = 128\n",
    "\n",
    "# 입력 이미지 placeholder\n",
    "X_A = tf.placeholder(tf.float32, shape=[None, X_dim])\n",
    "X_B = tf.placeholder(tf.float32, shape=[None, X_dim])\n",
    "\n",
    "\n",
    "# 판별자의 가중치와 편의(# 사비에르 초기치 사용)\n",
    "D_A_W1 = tf.get_variable('D_A_W1',shape=[X_dim, h_dim],initializer=tf.contrib.layers.xavier_initializer())\n",
    "D_A_b1 = tf.Variable(tf.zeros([h_dim]))\n",
    "D_A_W2 = tf.get_variable('D_A_W2', shape=[h_dim, 1],initializer=tf.contrib.layers.xavier_initializer())\n",
    "D_A_b2 = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "D_B_W1 = tf.get_variable('D_B_W1', shape=[X_dim, h_dim],initializer=tf.contrib.layers.xavier_initializer())\n",
    "D_B_b1 = tf.Variable(tf.zeros(shape=[h_dim]))\n",
    "D_B_W2 = tf.get_variable('D_B_W2', shape=[h_dim, 1],initializer=tf.contrib.layers.xavier_initializer())\n",
    "D_B_b2 = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "# 생성자의 가중치와 편의(# 사비에르 초기치 사용)\n",
    "G_AB_W1 = tf.get_variable('D_AB_W1', shape=[X_dim, h_dim],initializer=tf.contrib.layers.xavier_initializer())\n",
    "G_AB_b1 = tf.Variable(tf.zeros([h_dim]))\n",
    "G_AB_W2 = tf.get_variable('D_AB_W2', shape=[h_dim, X_dim],initializer=tf.contrib.layers.xavier_initializer())\n",
    "G_AB_b2 = tf.Variable(tf.zeros([X_dim]))\n",
    "\n",
    "G_BA_W1 = tf.get_variable('D_BA_W1', shape=[X_dim, h_dim],initializer=tf.contrib.layers.xavier_initializer())\n",
    "G_BA_b1 = tf.Variable(tf.zeros([h_dim]))\n",
    "G_BA_W2 = tf.get_variable('D_BA_W2', shape=[h_dim, X_dim],initializer=tf.contrib.layers.xavier_initializer())\n",
    "G_BA_b2 = tf.Variable(tf.zeros([X_dim]))\n",
    "\n",
    "\n",
    "# 모수 모음\n",
    "theta_DA = [D_A_W1, D_A_W2, D_A_b1, D_A_b2]\n",
    "theta_DB= [ D_B_W1, D_B_W2, D_B_b1, D_B_b2]\n",
    "theta_G = [G_AB_W1, G_AB_W2, G_AB_b1, G_AB_b2,\n",
    "           G_BA_W1, G_BA_W2, G_BA_b1, G_BA_b2]\n",
    "\n",
    "#------------------------------------------------\n",
    "# 생성자 정의:\n",
    "#------------------------------------------------\n",
    "def G_AB(X):\n",
    "    h1 = tf.nn.relu(tf.matmul(X, G_AB_W1) + G_AB_b1)\n",
    "    return tf.nn.sigmoid(tf.matmul(h1, G_AB_W2) + G_AB_b2)\n",
    "\n",
    "\n",
    "def G_BA(X):\n",
    "    h1 = tf.nn.relu(tf.matmul(X, G_BA_W1) + G_BA_b1)\n",
    "    return tf.nn.sigmoid(tf.matmul(h1, G_BA_W2) + G_BA_b2)\n",
    "\n",
    "#------------------------------------------------\n",
    "# 판별자 정의:\n",
    "#------------------------------------------------\n",
    "def D_A(X):\n",
    "    h1 = tf.nn.relu(tf.matmul(X, D_A_W1) + D_A_b1)\n",
    "    return tf.nn.sigmoid(tf.matmul(h1, D_A_W2) + D_A_b2)\n",
    "\n",
    "\n",
    "def D_B(X):\n",
    "    h1 = tf.nn.relu(tf.matmul(X, D_B_W1) + D_B_b1)\n",
    "    return tf.nn.sigmoid(tf.matmul(h1, D_B_W2) + D_B_b2)\n",
    "\n",
    "\n",
    "\n",
    "# 생성(변형)결과 \n",
    "X_AB = G_AB(X_A)\n",
    "X_BA = G_BA(X_B)\n",
    "\n",
    "\n",
    "# 판별자 D_A 결과 \n",
    "D_A_real = D_A(X_A)\n",
    "D_A_fake = D_A(X_BA)\n",
    "\n",
    "# 판별자 D_B 결과\n",
    "D_B_real = D_B(X_B)\n",
    "D_B_fake = D_B(X_AB)\n",
    "\n",
    "# 복원( x -> G(x)-> F(G(x)-> x))\n",
    "X_ABA = G_BA(X_AB)\n",
    "\n",
    "# 복원( y -> F(x)-> G(F(x)-> y))\n",
    "X_BAB = G_AB(X_BA)\n",
    "\n",
    "\n",
    "# 판별자 비용함수 (LSGAN 적용)\n",
    "DA_loss = 0.5 * (tf.reduce_mean((D_A_real - 1)**2)+ 0.5*tf.reduce_mean(D_A_fake**2))\n",
    "DB_loss = 0.5 * (tf.reduce_mean((D_B_real - 1)**2)+ 0.5*tf.reduce_mean(D_B_fake**2))\n",
    "\n",
    "# 생성자 비용함수\n",
    "GAB_loss = 0.5 * tf.reduce_mean((D_A_fake - 1)**2)+0.5 * tf.reduce_mean((D_B_fake - 1)**2)\n",
    "\n",
    "# 복원에 대한 비용함수\n",
    "C_loss=tf.reduce_mean(tf.abs(X_A-X_ABA))+tf.reduce_mean(tf.abs(X_B-X_BAB))\n",
    "G_loss=GAB_loss+C_loss\n",
    "\n",
    "\n",
    "# Optimizer\n",
    "DA_solver = tf.train.AdamOptimizer(learning_rate).minimize(DA_loss, var_list=theta_DA)\n",
    "DB_solver = tf.train.AdamOptimizer(learning_rate).minimize(DB_loss, var_list=theta_DB)\n",
    "G_solver = tf.train.AdamOptimizer(learning_rate).minimize(G_loss, var_list=theta_G)\n",
    "\n",
    "\n",
    "#------------------------------------------------\n",
    "# 텐서플로 그래프 생성 및 학습 \n",
    "#------------------------------------------------\n",
    "sess=tf.Session(); \n",
    "sess.run(tf.global_variables_initializer())\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    total_batch=int(sample_size/batch_size)\n",
    "    avg_loss=0\n",
    "    for ii in range(total_batch):\n",
    "        if ii!=total_batch:\n",
    "            d\n",
    "            \n",
    "            XrA=X_trainA[ii*batch_size:(ii+1)*batch_size]\n",
    "            XrB=X_trainB[ii*batch_size:(ii+1)*batch_size]\n",
    "        else:\n",
    "            XrA=X_trainA[(ii+1)*batch_size:]           \n",
    "            XrB=X_trainB[(ii+1)*batch_size:] \n",
    "            \n",
    "            DA_loss_curr,_ = sess.run([DA_loss,DA_solver], feed_dict={X_A: XrA, X_B: XrB})\n",
    "            DB_loss_curr,_ = sess.run([DB_loss,DB_solver], feed_dict={X_A: XrA, X_B: XrB})\n",
    "            G_loss_curr,_ = sess.run([G_loss,G_solver], feed_dict={X_A: XrA, X_B: XrB})    \n",
    "            losss=DA_loss_curr+DB_loss_curr+G_loss_curr\n",
    "            avg_loss+=losss/total_batch\n",
    "        print('Epoch: %d' %(epoch+1),'DiscriminatorA Loss= %f,DiscriminatorB Loss= %f, Generator Loss= %f, Avg Loss=%f' %(DA_loss_curr, DB_loss_curr,G_loss_curr, avg_loss))   \n",
    "        losses.append((DA_loss_curr, DB_loss_curr,G_loss_curr,avg_loss))\n",
    "        # 100 에폭마다 변형되는 이미지 그림\n",
    "        if (epoch+1)%100==0:  \n",
    "            samples_A = sess.run(X_BA, feed_dict={X_B: XB})\n",
    "            samples_B = sess.run(X_AB, feed_dict={X_A: XA})\n",
    "            # 도메인  A의 test 이미지\n",
    "            f,axes =plt.subplots(figsize=(7,7), nrows=1, ncols=2, sharey=True, sharex=True)\n",
    "            for ii in range(2):\n",
    "                plt.subplot(1,2,ii+1); plt.suptitle('Domain A') \n",
    "                plt.imshow(XA[ii].reshape(45,40),'Greys_r')\n",
    "            # G_AB(X_A) 결과               \n",
    "            f,axes =plt.subplots(figsize=(7,7), nrows=1, ncols=2, sharey=True, sharex=True)      \n",
    "            for ii in range(2):\n",
    "                plt.subplot(1,2,ii+1); plt.suptitle('Result of G_AB') \n",
    "                plt.imshow(samples_B[ii].reshape(40,45),'Greys_r')\n",
    "            # 도메인  B의 test 이미지\n",
    "            f,axes =plt.subplots(figsize=(7,7), nrows=1, ncols=2, sharey=True, sharex=True)\n",
    "            f.suptitle(epoch+1)\n",
    "            f.tight_layout()\n",
    "            for ii in range(2):\n",
    "                plt.subplot(1,2,ii+1);plt.suptitle('Domain B') \n",
    "                plt.imshow(XB[ii].reshape(40,45),'Greys_r')\n",
    "            # G_BA(X_B) 결과          \n",
    "            f,axes =plt.subplots(figsize=(7,7), nrows=1, ncols=2, sharey=True, sharex=True)     \n",
    "            for ii in range(2):\n",
    "                plt.subplot(1,2,ii+1);plt.suptitle('Result of G_BA') \n",
    "                plt.imshow(samples_A[ii].reshape(45,40),'Greys_r')  \n",
    "\n",
    "\n",
    "# 판별자, 생성자의 비용함수 그림 \n",
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "losses = np.array(losses)\n",
    "plt.plot(losses.T[0], label='DiscriminatorA')\n",
    "plt.plot(losses.T[1], label='DiscriminatorB')\n",
    "plt.plot(losses.T[2], label='Generator')\n",
    "plt.title(\"Training Losses\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "# 도메인 A 에 속하는 이미지\n",
    "f,axes =plt.subplots(figsize=(7,7), nrows=2, ncols=4, sharey=True, sharex=True)\n",
    "f.tight_layout()\n",
    "for ii in range(8):\n",
    "    plt.subplot(2,4,ii+1); f.suptitle('Domain A')\n",
    "    plt.imshow(X_trainA[ii].reshape(45,40),'Greys_r')\n",
    "\n",
    "# 도메인 B 에 속하는 이미지    \n",
    "f,axes =plt.subplots(figsize=(7,7), nrows=2, ncols=4, sharey=True, sharex=True)\n",
    "for ii in range(8):\n",
    "    plt.subplot(2,4,ii+1); f.suptitle('Domain B') \n",
    "    plt.imshow(X_trainB[ii].reshape(40,45),'Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Keras",
   "language": "python",
   "name": "keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
